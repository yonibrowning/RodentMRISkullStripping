{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716a1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "from RodentMRISkullStripping3D.rbm3.core.dice import dice_coef,dice_coef_loss\n",
    "from RodentMRISkullStripping3D.rbm3.core.utils import min_max_normalization, resample_img\n",
    "from RodentMRISkullStripping3D.rbm3.core.paras import PreParas, KerasParas\n",
    "from RodentMRISkullStripping3D.rbm3.scripts.rbm3 import brain_seg_prediction\n",
    "from RodentMRISkullStripping3D.rbm3.scripts.rbm3 import out_LabelHot_map_3D\n",
    "\n",
    "from pathlib import Path\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Custom code for cleaning up clutter.\n",
    "from skullstrippingutils import get_3d_paras,load_data_folder,get_dataset_partitions,resample_spacing,skull_strip_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2be98",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Default Parameters Preparation\n",
    "model_path = r\"C:\\Users\\yoni.browning\\OneDrive - Allen Institute\\Documents\\GitHub\\RodentMRISkullStripping\\yoniModelRetrain\\long_train_unet_3d-ROUND2_6Brain.h5\"\n",
    "pre_paras, keras_paras = get_3d_paras(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a51762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the pretrained model\n",
    "model = load_model(keras_paras.model_path,\n",
    "                         custom_objects={'dice_coef_loss': dice_coef_loss,\n",
    "                                         'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab99cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_folder(folder):\n",
    "    \"\"\"\n",
    "    Load data from folder. Folder must contain one and only one of each of:\n",
    "    (1) A .nii file with the with unprocessed data that includes the keyword \"raw\"\n",
    "    (2) A .nii file with the brain mask, which includes the keyword \"brain\"\n",
    "    Optionally, there can also be a \n",
    "    (3) A .nii file that contains the keyword \"outline.\" This will allow seperate outline labeling,\n",
    "    BUT it is really an antiquated thing I tried and isn't needed. It will only be used\n",
    "    if the variable \"use_outline\" is true\n",
    "    \n",
    "    Additional input resolution specifies the image resolution (some .nii files do not include this).\n",
    "    Default is .1(mm)\n",
    "    \n",
    "    Outputs:\n",
    "    Img = sitk Image with raw nii information\n",
    "    Lbl = sitk Image with training labels for Img\n",
    "    \"\"\"\n",
    "    fls = os.listdir(folder)\n",
    "    for ii,flname in enumerate(fls):\n",
    "        if 'cropped.nii' in flname:\n",
    "            Img = sitk.ReadImage(os.path.join(folder,flname))\n",
    "        if 'mask.nii' in flname:\n",
    "            Brn = sitk.ReadImage(os.path.join(folder,flname))\n",
    "            brn = sitk.GetArrayFromImage(Brn)\n",
    "            brn = (brn-np.min(brn))/(np.max(brn)-np.min(brn))\n",
    "            brn = (brn>.5).astype(np.float32)\n",
    "\n",
    "        \n",
    "    lbl = np.zeros(brn.shape,dtype = np.float32)\n",
    "    lbl[brn>0]=1\n",
    "    Lbl = sitk.GetImageFromArray(lbl)\n",
    "    Lbl.SetSpacing([resolution]*3)\n",
    "    return Img,Lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3046660",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters \n",
    "patch_dims = pre_paras.patch_dims\n",
    "label_dims = pre_paras.patch_label_dims\n",
    "strides = pre_paras.patch_strides\n",
    "n_class = pre_paras.n_class\n",
    "\n",
    "# Choose which augmentation we want\n",
    "do_resample_augment = False\n",
    "do_contrast_augment = False\n",
    "\n",
    "# Preprocess the images for fitting\n",
    "data_folder = r'D:\\MRI\\Qiu_et_al'\n",
    "image_folder_list = ['F11','M15']\n",
    "    \n",
    "Images = []\n",
    "Labels = []\n",
    "for ii, image_folder in enumerate(image_folder_list):\n",
    "    print(image_folder)\n",
    "    Img,Lbl = load_data_folder(os.path.join(data_folder,image_folder),use_outline = False)\n",
    "    # Default resolution patches and labels\n",
    "    img = sitk.GetArrayFromImage(Img)\n",
    "    img = min_max_normalization(img)\n",
    "    Images.append(img)\n",
    "   \n",
    "    lbl = sitk.GetArrayFromImage(Lbl)\n",
    "    Labels.append(lbl)\n",
    "    \n",
    "    # This is where we should do some data augmentation\n",
    "    # Ultimately, these should be functionalized s.t. we can combine them\n",
    "    if do_resample_augment:\n",
    "    # (1) small changes in the brain resolution. \n",
    "    # B.c. the model is trained explicitly on 64x64x64 image, this effectivly mimics \n",
    "    # a smaller or larger brain\n",
    "        re_Img,re_Lbl = resample_spacing(Img,Lbl,[.09,.09,.09])\n",
    "        Images.append(re_Img)\n",
    "        Labels.append(re_Lbl)\n",
    "        \n",
    "        re_Img,re_Lbl = resample_spacing(Img,Lbl,[.11,.11,.11])\n",
    "        Images.append(re_Img)\n",
    "        Labels.append(re_Lbl)\n",
    "        \n",
    "    # (2) changes in contrast\n",
    "    if do_contrast_augment: \n",
    "        from skimage.exposure import adjust_gamma\n",
    "        # Similarly, do gamma adjustment to fiddle with contrast\n",
    "        g_img = adjust_gamma(img,.9)\n",
    "        g_img = min_max_normalization(g_img)\n",
    "        Images.append(g_img)\n",
    "        Labels.append(lbl)\n",
    "        \n",
    "        gImg = sitk.GetImageFromArry()\n",
    "        gImg.SetSpacing([.01]*3)\n",
    "        \n",
    "        re_Img,re_Lbl = resample_spacing(Img,Lbl,[.09,.09,.09])\n",
    "        Images.append(re_Img)\n",
    "        Labels.append(re_Lbl)\n",
    "        \n",
    "        re_Img,re_Lbl = resample_spacing(gImg,Lbl,[.11,.11,.11])\n",
    "        Images.append(re_Img)\n",
    "        Labels.append(re_Lbl)\n",
    "        \n",
    "        # Similarly, do gamma adjustment to fiddle with contrast\n",
    "        g_img = adjust_gamma(img,1.1)\n",
    "        g_img = min_max_normalization(g_img)\n",
    "        Images.append(g_img)\n",
    "        Labels.append(lbl)\n",
    "        \n",
    "        gImg = sitk.GetImageFromArry()\n",
    "        gImg.SetSpacing([.01]*3)\n",
    "        \n",
    "        re_Img,re_Lbl = resample_spacing(Img,Lbl,[.09,.09,.09])\n",
    "        Images.append(re_Img)\n",
    "        Labels.append(re_Lbl)\n",
    "        \n",
    "        re_Img,re_Lbl = resample_spacing(gImg,Lbl,[.11,.11,.11])\n",
    "        Images.append(re_Img)\n",
    "        Labels.append(re_Lbl)\n",
    "\n",
    "    # (3) rotations/transposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "patches = []\n",
    "labels = []\n",
    "\n",
    "    \n",
    "# Prep data for training\n",
    "for ii,img in enumerate(Images):\n",
    "    lbl = Labels[ii]\n",
    "    # Load the Image & Labels, convert to numpy\n",
    "    length, col, row = img.shape\n",
    "    categorical_map = np.zeros((n_class, length, col, row), dtype=np.uint8)\n",
    "    likelihood_map = np.zeros((length, col, row), dtype=np.float32)\n",
    "    counter_map = np.zeros((length,col,row), dtype=np.float32)\n",
    "    \n",
    "    for i in range(0, length-patch_dims[0]+1, strides[0]):\n",
    "        for j in range(0, col-patch_dims[1]+1, strides[1]):\n",
    "            for k in range(0, row-patch_dims[2]+1, strides[2]):\n",
    "                cur_patch=img[i:i+patch_dims[0],\n",
    "                              j:j+patch_dims[1],\n",
    "                              k:k+patch_dims[2]][:].reshape([1,1,\n",
    "                                                             patch_dims[0],\n",
    "                                                             patch_dims[1],\n",
    "                                                             patch_dims[2]])\n",
    "                cur_patch = np.transpose(cur_patch, (0, 2, 3, 4, 1))\n",
    "\n",
    "                cur_labels=lbl[i:i+patch_dims[0],\n",
    "                              j:j+patch_dims[1],\n",
    "                              k:k+patch_dims[2]][:].reshape([1,1,\n",
    "                                                             patch_dims[0],\n",
    "                                                             patch_dims[1],\n",
    "                                                             patch_dims[2]])\n",
    "                cur_labels = np.transpose(cur_labels, (0, 2, 3, 4, 1))\n",
    "\n",
    "                patches.append(cur_patch)\n",
    "                labels.append(cur_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.learning_rate = 1E-5 # Default was 1e-10-->this is a big speed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training/validation data. No test data is returned.\n",
    "train_x,train_y,val_x,val_y,_,_ = get_dataset_partitions(patches,labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75777159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model; This gets its own cell so that we can see outputs print :/\n",
    "history  = model.fit(x = np.vstack(train_x),y = np.vstack(train_y),\n",
    "                     epochs=30,verbose=1,validation_data =(np.vstack(val_x),np.vstack(val_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f47b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output.\n",
    "save_path  =r'C:\\Users\\yoni.browning\\OneDrive - Allen Institute\\Documents\\GitHub\\RodentMRISkullStripping\\yoniModelRetrain\\long_train_unet_3d-ROUND2_6Brain.h5'\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a684c97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations:0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "Number of iterations:80\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "# Skull strip an individual file.\n",
    "input_path =r'D:\\MRI\\Que_et_al\\M15\\M15_cropped.nii'\n",
    "output_path =  r'D:\\MRI\\Que_et_al\\M15\\M15_cropped_auto_skull_strip.nii'\n",
    "voxsize = .1\n",
    "mask,img = skull_strip_file(input_path,output_path,model_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e190711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path  =r'C:\\Users\\yoni.browning\\OneDrive - Allen Institute\\Documents\\GitHub\\RodentMRISkullStripping\\yoniModelRetrain\\long_train_unet_3d-ROUND2_6Brain.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3ffab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
